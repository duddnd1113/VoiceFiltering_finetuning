{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21aac941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enh_model.separator.conformer.embed.0.weight', 'enh_model.separator.conformer.embed.0.bias', 'enh_model.separator.conformer.embed.1.weight', 'enh_model.separator.conformer.embed.1.bias', 'enh_model.separator.conformer.encoders.0.self_attn.pos_bias_u', 'enh_model.separator.conformer.encoders.0.self_attn.pos_bias_v', 'enh_model.separator.conformer.encoders.0.self_attn.linear_q.weight', 'enh_model.separator.conformer.encoders.0.self_attn.linear_q.bias', 'enh_model.separator.conformer.encoders.0.self_attn.linear_k.weight', 'enh_model.separator.conformer.encoders.0.self_attn.linear_k.bias', 'enh_model.separator.conformer.encoders.0.self_attn.linear_v.weight', 'enh_model.separator.conformer.encoders.0.self_attn.linear_v.bias', 'enh_model.separator.conformer.encoders.0.self_attn.linear_out.weight', 'enh_model.separator.conformer.encoders.0.self_attn.linear_out.bias', 'enh_model.separator.conformer.encoders.0.self_attn.linear_pos.weight', 'enh_model.separator.conformer.encoders.0.feed_forward.w_1.weight', 'enh_model.separator.conformer.encoders.0.feed_forward.w_1.bias', 'enh_model.separator.conformer.encoders.0.feed_forward.w_2.weight', 'enh_model.separator.conformer.encoders.0.feed_forward.w_2.bias', 'enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_1.weight', 'enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_1.bias', 'enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_2.weight', 'enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_2.bias', 'enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv1.weight', 'enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv1.bias', 'enh_model.separator.conformer.encoders.0.conv_module.depthwise_conv.weight', 'enh_model.separator.conformer.encoders.0.conv_module.depthwise_conv.bias', 'enh_model.separator.conformer.encoders.0.conv_module.norm.weight', 'enh_model.separator.conformer.encoders.0.conv_module.norm.bias', 'enh_model.separator.conformer.encoders.0.conv_module.norm.running_mean', 'enh_model.separator.conformer.encoders.0.conv_module.norm.running_var', 'enh_model.separator.conformer.encoders.0.conv_module.norm.num_batches_tracked', 'enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv2.weight', 'enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv2.bias', 'enh_model.separator.conformer.encoders.0.norm_ff.weight', 'enh_model.separator.conformer.encoders.0.norm_ff.bias', 'enh_model.separator.conformer.encoders.0.norm_mha.weight', 'enh_model.separator.conformer.encoders.0.norm_mha.bias', 'enh_model.separator.conformer.encoders.0.norm_ff_macaron.weight', 'enh_model.separator.conformer.encoders.0.norm_ff_macaron.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/88x5v8pj1h3g803rndft70xr0000gn/T/ipykernel_62765/3533509166.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"pretrained/pytorch_model.bin\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state = torch.load(\"pretrained/pytorch_model.bin\", map_location=\"cpu\")\n",
    "print(list(state.keys())[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce97307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/88x5v8pj1h3g803rndft70xr0000gn/T/ipykernel_62765/1356290778.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"pretrained/pytorch_model.bin\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enh_model.separator.conformer.embed.0.weight\n",
      "enh_model.separator.conformer.embed.0.bias\n",
      "enh_model.separator.conformer.embed.1.weight\n",
      "enh_model.separator.conformer.embed.1.bias\n",
      "enh_model.separator.conformer.encoders.0.self_attn.pos_bias_u\n",
      "enh_model.separator.conformer.encoders.0.self_attn.pos_bias_v\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_q.weight\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_q.bias\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_k.weight\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_k.bias\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_v.weight\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_v.bias\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_out.weight\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_out.bias\n",
      "enh_model.separator.conformer.encoders.0.self_attn.linear_pos.weight\n",
      "enh_model.separator.conformer.encoders.0.feed_forward.w_1.weight\n",
      "enh_model.separator.conformer.encoders.0.feed_forward.w_1.bias\n",
      "enh_model.separator.conformer.encoders.0.feed_forward.w_2.weight\n",
      "enh_model.separator.conformer.encoders.0.feed_forward.w_2.bias\n",
      "enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_1.weight\n",
      "enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_1.bias\n",
      "enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_2.weight\n",
      "enh_model.separator.conformer.encoders.0.feed_forward_macaron.w_2.bias\n",
      "enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv1.weight\n",
      "enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv1.bias\n",
      "enh_model.separator.conformer.encoders.0.conv_module.depthwise_conv.weight\n",
      "enh_model.separator.conformer.encoders.0.conv_module.depthwise_conv.bias\n",
      "enh_model.separator.conformer.encoders.0.conv_module.norm.weight\n",
      "enh_model.separator.conformer.encoders.0.conv_module.norm.bias\n",
      "enh_model.separator.conformer.encoders.0.conv_module.norm.running_mean\n",
      "enh_model.separator.conformer.encoders.0.conv_module.norm.running_var\n",
      "enh_model.separator.conformer.encoders.0.conv_module.norm.num_batches_tracked\n",
      "enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv2.weight\n",
      "enh_model.separator.conformer.encoders.0.conv_module.pointwise_conv2.bias\n",
      "enh_model.separator.conformer.encoders.0.norm_ff.weight\n",
      "enh_model.separator.conformer.encoders.0.norm_ff.bias\n",
      "enh_model.separator.conformer.encoders.0.norm_mha.weight\n",
      "enh_model.separator.conformer.encoders.0.norm_mha.bias\n",
      "enh_model.separator.conformer.encoders.0.norm_ff_macaron.weight\n",
      "enh_model.separator.conformer.encoders.0.norm_ff_macaron.bias\n",
      "enh_model.separator.conformer.encoders.0.norm_conv.weight\n",
      "enh_model.separator.conformer.encoders.0.norm_conv.bias\n",
      "enh_model.separator.conformer.encoders.0.norm_final.weight\n",
      "enh_model.separator.conformer.encoders.0.norm_final.bias\n",
      "enh_model.separator.conformer.encoders.1.self_attn.pos_bias_u\n",
      "enh_model.separator.conformer.encoders.1.self_attn.pos_bias_v\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_q.weight\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_q.bias\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_k.weight\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_k.bias\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_v.weight\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_v.bias\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_out.weight\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_out.bias\n",
      "enh_model.separator.conformer.encoders.1.self_attn.linear_pos.weight\n",
      "enh_model.separator.conformer.encoders.1.feed_forward.w_1.weight\n",
      "enh_model.separator.conformer.encoders.1.feed_forward.w_1.bias\n",
      "enh_model.separator.conformer.encoders.1.feed_forward.w_2.weight\n",
      "enh_model.separator.conformer.encoders.1.feed_forward.w_2.bias\n",
      "enh_model.separator.conformer.encoders.1.feed_forward_macaron.w_1.weight\n",
      "enh_model.separator.conformer.encoders.1.feed_forward_macaron.w_1.bias\n",
      "enh_model.separator.conformer.encoders.1.feed_forward_macaron.w_2.weight\n",
      "enh_model.separator.conformer.encoders.1.feed_forward_macaron.w_2.bias\n",
      "enh_model.separator.conformer.encoders.1.conv_module.pointwise_conv1.weight\n",
      "enh_model.separator.conformer.encoders.1.conv_module.pointwise_conv1.bias\n",
      "enh_model.separator.conformer.encoders.1.conv_module.depthwise_conv.weight\n",
      "enh_model.separator.conformer.encoders.1.conv_module.depthwise_conv.bias\n",
      "enh_model.separator.conformer.encoders.1.conv_module.norm.weight\n",
      "enh_model.separator.conformer.encoders.1.conv_module.norm.bias\n",
      "enh_model.separator.conformer.encoders.1.conv_module.norm.running_mean\n",
      "enh_model.separator.conformer.encoders.1.conv_module.norm.running_var\n",
      "enh_model.separator.conformer.encoders.1.conv_module.norm.num_batches_tracked\n",
      "enh_model.separator.conformer.encoders.1.conv_module.pointwise_conv2.weight\n",
      "enh_model.separator.conformer.encoders.1.conv_module.pointwise_conv2.bias\n",
      "enh_model.separator.conformer.encoders.1.norm_ff.weight\n",
      "enh_model.separator.conformer.encoders.1.norm_ff.bias\n",
      "enh_model.separator.conformer.encoders.1.norm_mha.weight\n",
      "enh_model.separator.conformer.encoders.1.norm_mha.bias\n",
      "enh_model.separator.conformer.encoders.1.norm_ff_macaron.weight\n",
      "enh_model.separator.conformer.encoders.1.norm_ff_macaron.bias\n",
      "enh_model.separator.conformer.encoders.1.norm_conv.weight\n",
      "enh_model.separator.conformer.encoders.1.norm_conv.bias\n",
      "enh_model.separator.conformer.encoders.1.norm_final.weight\n",
      "enh_model.separator.conformer.encoders.1.norm_final.bias\n",
      "enh_model.separator.conformer.encoders.2.self_attn.pos_bias_u\n",
      "enh_model.separator.conformer.encoders.2.self_attn.pos_bias_v\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_q.weight\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_q.bias\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_k.weight\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_k.bias\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_v.weight\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_v.bias\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_out.weight\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_out.bias\n",
      "enh_model.separator.conformer.encoders.2.self_attn.linear_pos.weight\n",
      "enh_model.separator.conformer.encoders.2.feed_forward.w_1.weight\n",
      "enh_model.separator.conformer.encoders.2.feed_forward.w_1.bias\n",
      "enh_model.separator.conformer.encoders.2.feed_forward.w_2.weight\n",
      "enh_model.separator.conformer.encoders.2.feed_forward.w_2.bias\n",
      "enh_model.separator.conformer.encoders.2.feed_forward_macaron.w_1.weight\n",
      "enh_model.separator.conformer.encoders.2.feed_forward_macaron.w_1.bias\n",
      "enh_model.separator.conformer.encoders.2.feed_forward_macaron.w_2.weight\n",
      "enh_model.separator.conformer.encoders.2.feed_forward_macaron.w_2.bias\n",
      "enh_model.separator.conformer.encoders.2.conv_module.pointwise_conv1.weight\n",
      "enh_model.separator.conformer.encoders.2.conv_module.pointwise_conv1.bias\n",
      "enh_model.separator.conformer.encoders.2.conv_module.depthwise_conv.weight\n",
      "enh_model.separator.conformer.encoders.2.conv_module.depthwise_conv.bias\n",
      "enh_model.separator.conformer.encoders.2.conv_module.norm.weight\n",
      "enh_model.separator.conformer.encoders.2.conv_module.norm.bias\n",
      "enh_model.separator.conformer.encoders.2.conv_module.norm.running_mean\n",
      "enh_model.separator.conformer.encoders.2.conv_module.norm.running_var\n",
      "enh_model.separator.conformer.encoders.2.conv_module.norm.num_batches_tracked\n",
      "enh_model.separator.conformer.encoders.2.conv_module.pointwise_conv2.weight\n",
      "enh_model.separator.conformer.encoders.2.conv_module.pointwise_conv2.bias\n",
      "enh_model.separator.conformer.encoders.2.norm_ff.weight\n",
      "enh_model.separator.conformer.encoders.2.norm_ff.bias\n",
      "enh_model.separator.conformer.encoders.2.norm_mha.weight\n",
      "enh_model.separator.conformer.encoders.2.norm_mha.bias\n",
      "enh_model.separator.conformer.encoders.2.norm_ff_macaron.weight\n",
      "enh_model.separator.conformer.encoders.2.norm_ff_macaron.bias\n",
      "enh_model.separator.conformer.encoders.2.norm_conv.weight\n",
      "enh_model.separator.conformer.encoders.2.norm_conv.bias\n",
      "enh_model.separator.conformer.encoders.2.norm_final.weight\n",
      "enh_model.separator.conformer.encoders.2.norm_final.bias\n",
      "enh_model.separator.conformer.encoders.3.self_attn.pos_bias_u\n",
      "enh_model.separator.conformer.encoders.3.self_attn.pos_bias_v\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_q.weight\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_q.bias\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_k.weight\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_k.bias\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_v.weight\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_v.bias\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_out.weight\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_out.bias\n",
      "enh_model.separator.conformer.encoders.3.self_attn.linear_pos.weight\n",
      "enh_model.separator.conformer.encoders.3.feed_forward.w_1.weight\n",
      "enh_model.separator.conformer.encoders.3.feed_forward.w_1.bias\n",
      "enh_model.separator.conformer.encoders.3.feed_forward.w_2.weight\n",
      "enh_model.separator.conformer.encoders.3.feed_forward.w_2.bias\n",
      "enh_model.separator.conformer.encoders.3.feed_forward_macaron.w_1.weight\n",
      "enh_model.separator.conformer.encoders.3.feed_forward_macaron.w_1.bias\n",
      "enh_model.separator.conformer.encoders.3.feed_forward_macaron.w_2.weight\n",
      "enh_model.separator.conformer.encoders.3.feed_forward_macaron.w_2.bias\n",
      "enh_model.separator.conformer.encoders.3.conv_module.pointwise_conv1.weight\n",
      "enh_model.separator.conformer.encoders.3.conv_module.pointwise_conv1.bias\n",
      "enh_model.separator.conformer.encoders.3.conv_module.depthwise_conv.weight\n",
      "enh_model.separator.conformer.encoders.3.conv_module.depthwise_conv.bias\n",
      "enh_model.separator.conformer.encoders.3.conv_module.norm.weight\n",
      "enh_model.separator.conformer.encoders.3.conv_module.norm.bias\n",
      "enh_model.separator.conformer.encoders.3.conv_module.norm.running_mean\n",
      "enh_model.separator.conformer.encoders.3.conv_module.norm.running_var\n",
      "enh_model.separator.conformer.encoders.3.conv_module.norm.num_batches_tracked\n",
      "enh_model.separator.conformer.encoders.3.conv_module.pointwise_conv2.weight\n",
      "enh_model.separator.conformer.encoders.3.conv_module.pointwise_conv2.bias\n",
      "enh_model.separator.conformer.encoders.3.norm_ff.weight\n",
      "enh_model.separator.conformer.encoders.3.norm_ff.bias\n",
      "enh_model.separator.conformer.encoders.3.norm_mha.weight\n",
      "enh_model.separator.conformer.encoders.3.norm_mha.bias\n",
      "enh_model.separator.conformer.encoders.3.norm_ff_macaron.weight\n",
      "enh_model.separator.conformer.encoders.3.norm_ff_macaron.bias\n",
      "enh_model.separator.conformer.encoders.3.norm_conv.weight\n",
      "enh_model.separator.conformer.encoders.3.norm_conv.bias\n",
      "enh_model.separator.conformer.encoders.3.norm_final.weight\n",
      "enh_model.separator.conformer.encoders.3.norm_final.bias\n",
      "enh_model.separator.linear.0.weight\n",
      "enh_model.separator.linear.0.bias\n",
      "filter_condition_transform.weight\n",
      "filter_condition_transform.bias\n",
      "xvector_model.sincnet.wav_norm1d.weight\n",
      "xvector_model.sincnet.wav_norm1d.bias\n",
      "xvector_model.sincnet.conv1d.0.filterbank.low_hz_\n",
      "xvector_model.sincnet.conv1d.0.filterbank.band_hz_\n",
      "xvector_model.sincnet.conv1d.0.filterbank.window_\n",
      "xvector_model.sincnet.conv1d.0.filterbank.n_\n",
      "xvector_model.sincnet.conv1d.1.weight\n",
      "xvector_model.sincnet.conv1d.1.bias\n",
      "xvector_model.sincnet.conv1d.2.weight\n",
      "xvector_model.sincnet.conv1d.2.bias\n",
      "xvector_model.sincnet.norm1d.0.weight\n",
      "xvector_model.sincnet.norm1d.0.bias\n",
      "xvector_model.sincnet.norm1d.1.weight\n",
      "xvector_model.sincnet.norm1d.1.bias\n",
      "xvector_model.sincnet.norm1d.2.weight\n",
      "xvector_model.sincnet.norm1d.2.bias\n",
      "xvector_model.tdnns.0.weight\n",
      "xvector_model.tdnns.0.bias\n",
      "xvector_model.tdnns.2.weight\n",
      "xvector_model.tdnns.2.bias\n",
      "xvector_model.tdnns.2.running_mean\n",
      "xvector_model.tdnns.2.running_var\n",
      "xvector_model.tdnns.2.num_batches_tracked\n",
      "xvector_model.tdnns.3.weight\n",
      "xvector_model.tdnns.3.bias\n",
      "xvector_model.tdnns.5.weight\n",
      "xvector_model.tdnns.5.bias\n",
      "xvector_model.tdnns.5.running_mean\n",
      "xvector_model.tdnns.5.running_var\n",
      "xvector_model.tdnns.5.num_batches_tracked\n",
      "xvector_model.tdnns.6.weight\n",
      "xvector_model.tdnns.6.bias\n",
      "xvector_model.tdnns.8.weight\n",
      "xvector_model.tdnns.8.bias\n",
      "xvector_model.tdnns.8.running_mean\n",
      "xvector_model.tdnns.8.running_var\n",
      "xvector_model.tdnns.8.num_batches_tracked\n",
      "xvector_model.tdnns.9.weight\n",
      "xvector_model.tdnns.9.bias\n",
      "xvector_model.tdnns.11.weight\n",
      "xvector_model.tdnns.11.bias\n",
      "xvector_model.tdnns.11.running_mean\n",
      "xvector_model.tdnns.11.running_var\n",
      "xvector_model.tdnns.11.num_batches_tracked\n",
      "xvector_model.tdnns.12.weight\n",
      "xvector_model.tdnns.12.bias\n",
      "xvector_model.tdnns.14.weight\n",
      "xvector_model.tdnns.14.bias\n",
      "xvector_model.tdnns.14.running_mean\n",
      "xvector_model.tdnns.14.running_var\n",
      "xvector_model.tdnns.14.num_batches_tracked\n",
      "xvector_model.embedding.weight\n",
      "xvector_model.embedding.bias\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(\"pretrained/pytorch_model.bin\", map_location=\"cpu\")\n",
    "\n",
    "for k in state.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9ad8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
